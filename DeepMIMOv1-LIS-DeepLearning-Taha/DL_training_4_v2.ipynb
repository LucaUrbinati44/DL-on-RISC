{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a77e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, ReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard, ProgbarLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import os\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70c64d-2e2a-4c78-92da-c841335d0364",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'C:/Users/Work/Desktop/deepMIMO/RIS/DeepMIMOv1-LIS-DeepLearning-Taha/'\n",
    "output_folder = base_folder+'Output Python/'\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "\n",
    "simulate_data = 1\n",
    "\n",
    "if simulate_data == 1:\n",
    "    # Simulated data for testing purposes\n",
    "    #dataset_size = 100\n",
    "    #training_size = 80 \n",
    "    #validation_size = 20\n",
    "    #M = 8\n",
    "else:\n",
    "    #dataset_size = 36200\n",
    "    #training_size = 30000\n",
    "    #validation_size = 6200\n",
    "    #M = 64*64 # 4096\n",
    "\n",
    "#DL_input_reshaped = np.random.rand(M, 1, 1, dataset_size) \n",
    "#DL_output_reshaped = np.random.rand(1, 1, M, dataset_size)\n",
    "\n",
    "#TODO: import data already split in matlab for testing the nn first\n",
    "\n",
    "\n",
    "print(f\"First sample: {DL_input_reshaped[:,0,0,0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af43ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Configurazione GPU ------------------ #\n",
    "if not use_gpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disabilita la GPU\n",
    "print(f\"Using GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# ------------------ Preprocessing and Dataset Splitting ------------------ #\n",
    "print(f\"---> DL Beamforming for Training_Size {training_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f45e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the input and output arrays if necessary\n",
    "#X = DL_input_reshaped.reshape(DL_input_reshaped.shape[0], -1).astype(np.float32)\n",
    "#Y = DL_output_reshaped.reshape(DL_output_reshaped.shape[0], -1).astype(np.float32)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "#X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=validation_size / (training_size + validation_size), shuffle=False, random_state=seed)\n",
    "#XTrain = np.array(DL_input_reshaped[:, 0, 0, Training_Ind], dtype=np.float32)\n",
    "#YTrain = np.array(DL_output_reshaped[0, 0, :, Training_Ind], dtype=np.float32)\n",
    "#XValidation = np.array(DL_input_reshaped[:, 0, 0, Validation_Ind], dtype=np.float32)\n",
    "#YValidation = np.array(DL_output_reshaped[0, 0, :, Validation_Ind], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28538b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the training data (zero-center normalization)\n",
    "# Documentation StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "#  with_mean: default=True, If True, center the data before scaling. \n",
    "#  with_std: default=True, If True, scale the data to unit variance (or equivalently, unit standard deviation).\n",
    "scaler = StandardScaler(with_std=False) # To match Matlab imageInputLayer normalization behavior\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "print(f\"Scaler: scale: {scaler.scale_}, mean: {scaler.mean_}, var: {scaler.var_}, n_features_in_: {scaler.n_features_in_}, n_samples_seen_: {scaler.n_samples_seen_}\")\n",
    "\n",
    "# Apply the same scaling to the validation data\n",
    "X_val = scaler.transform(X_val)  # Transform the validation data using the same scaler\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}, Validation set size: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd1da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DL Model Definition ------------------ #\n",
    "# Define the neural network architecture\n",
    "model = Sequential([\n",
    "    Dense(units=Y_train.shape[1], input_shape=(X_train.shape[1],), kernel_regularizer=l2(1e-4), name='Fully1'),\n",
    "    ReLU(name='relu1'),\n",
    "    Dropout(0.5, name='dropout1'),\n",
    "\n",
    "    Dense(units=4 * Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully2'),\n",
    "    ReLU(name='relu2'),\n",
    "    Dropout(0.5, name='dropout2'),\n",
    "\n",
    "    Dense(units=4 * Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully3'),\n",
    "    ReLU(name='relu3'),\n",
    "    Dropout(0.5, name='dropout3'),\n",
    "\n",
    "    Dense(units=Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully4'),\n",
    "])\n",
    "\n",
    "# Compile the model with SGD optimizer and mean squared error loss\n",
    "optimizer = SGD(learning_rate=1e-1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "# ------------------ Learning Rate Scheduler ------------------ #\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch > 0 and epoch % 3 == 0:\n",
    "        return lr * 0.5  # Drop learning rate by factor of 0.5 every 3 epochs\n",
    "    return lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# ------------------ TensorBoard Callback ------------------ #\n",
    "tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "\n",
    "# ------------------ Training Options ------------------ #\n",
    "verbose_frequency = max(1, training_size // mini_batch_size)\n",
    "progbar_logger = ProgbarLogger(count_mode='samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DL Model Training ------------------ #\n",
    "print(\"Start DL training...\")\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    batch_size=mini_batch_size,\n",
    "    epochs=max_epochs,\n",
    "    shuffle=True,  # Shuffle data at each epoch\n",
    "    callbacks=[lr_scheduler, tensorboard_callback, progbar_logger],\n",
    "    verbose=1\n",
    ")\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Training completed in {elapsed_time / 60:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ac6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ DL Model Prediction ------------------ #\n",
    "print(\"Start DL prediction for Figure 12...\")\n",
    "Y_predicted = model.predict(X_val)\n",
    "print(\"Done\")\n",
    "\n",
    "print(f\"Predicted output shape: {Y_predicted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4fb83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved as 'trained_model.h5'\")\n",
    "\n",
    "# Save history and Y_predicted in .mat format to be imported in Matlab later\n",
    "sio.savemat(output_folder + 'history.mat', {'history': history.history})\n",
    "sio.savemat(output_folder + 'Y_predicted.mat', {'Y_predicted': Y_predicted})\n",
    "print(f\"Y_predicted saved as 'Y_predicted.mat' in {output_folder}\")\n",
    "\n",
    "#np.save(os.path.join(output_folder, 'history.npy'), history.history)\n",
    "#np.save(os.path.join(output_folder, 'Y_predicted.npy'), Y_predicted)\n",
    "#print(\"History and Y_predicted saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d467b325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba063c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4e01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e928084-71b4-4ae8-b097-47c2b1d40c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=validation_size / (training_size + validation_size), random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b262e523-ea71-46e5-b463-ee09375768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a850c4e4-2fff-460d-b2be-d47a782cc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrivi un array a e b per usare train_test_split\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, Y_val = train_test_split(a,b,test_size=0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c6ec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fc106-6620-4fb4-bd7a-18dfbc49978b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepmimo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
