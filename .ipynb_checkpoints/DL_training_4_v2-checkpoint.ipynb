{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b5012b1-c233-49f2-a3a7-3d887507d284",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 15:10:15.797866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743772215.895731     837 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743772215.926359     837 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743772216.124344     837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743772216.124408     837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743772216.124412     837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743772216.124414     837 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, ReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, TensorBoard, ProgbarLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import os\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fafcd873-f978-4e5e-94b8-8727c972fd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione principale per l'allenamento del modello DL\n",
    "def dl_training_4(DL_input_reshaped, DL_output_reshaped, training_size, validation_size, mini_batch_size=500, max_epochs=20, use_gpu=True):\n",
    "    \"\"\"\n",
    "    DL Beamforming Training Script\n",
    "    Args:\n",
    "        DL_input_reshaped (numpy.ndarray): Input reshaped dataset (features).\n",
    "        DL_output_reshaped (numpy.ndarray): Output reshaped dataset (labels).\n",
    "        training_size (int): Number of samples for training.\n",
    "        validation_size (int): Number of samples for validation.\n",
    "        mini_batch_size (int): Size of the minibatch for training.\n",
    "        max_epochs (int): Maximum number of epochs for training.\n",
    "        use_gpu (bool): Flag to enable or disable GPU usage.\n",
    "    Returns:\n",
    "        model (tensorflow.keras.Model): Trained Keras model.\n",
    "        history (tensorflow.keras.callbacks.History): Training history.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------ Configurazione GPU ------------------ #\n",
    "    if not use_gpu:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # Disabilita la GPU\n",
    "    print(f\"Using GPU: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "    # ------------------ Preprocessing and Dataset Splitting ------------------ #\n",
    "    print(f\"---> DL Beamforming for Training_Size {training_size}\")\n",
    "\n",
    "    # Flatten the input and output arrays if necessary\n",
    "    X = DL_input_reshaped.reshape(DL_input_reshaped.shape[0], -1).astype(np.float32)\n",
    "    Y = DL_output_reshaped.reshape(DL_output_reshaped.shape[0], -1).astype(np.float32)\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=validation_size / (training_size + validation_size), random_state=42)\n",
    "\n",
    "    # Normalize the training data (zero-center normalization)\n",
    "    # Documentation StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "    #  with_mean: default=True, If True, center the data before scaling. \n",
    "    #  with_std: default=True, If True, scale the data to unit variance (or equivalently, unit standard deviation).\n",
    "    scaler = StandardScaler(with_std=False) # To match Matlab imageInputLayer normalization behavior\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    print(f\"Scaler: scale: {scaler.scale_}, mean: {scaler.mean_}, var: {scaler.var_}, n_features_in_: {scaler.n_features_in_}, n_samples_seen_: {scaler.n_samples_seen_}\")\n",
    "    \n",
    "    # Apply the same scaling to the validation data\n",
    "    X_val = scaler.transform(X_val)  # Transform the validation data using the same scaler\n",
    "\n",
    "    print(f\"Training set size: {X_train.shape}, Validation set size: {X_val.shape}\")\n",
    "\n",
    "    # ------------------ DL Model Definition ------------------ #\n",
    "    # Define the neural network architecture\n",
    "    model = Sequential([\n",
    "        Dense(units=Y_train.shape[1], input_shape=(X_train.shape[1],), kernel_regularizer=l2(1e-4), name='Fully1'),\n",
    "        ReLU(name='relu1'),\n",
    "        Dropout(0.5, name='dropout1'),\n",
    "\n",
    "        Dense(units=4 * Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully2'),\n",
    "        ReLU(name='relu2'),\n",
    "        Dropout(0.5, name='dropout2'),\n",
    "\n",
    "        Dense(units=4 * Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully3'),\n",
    "        ReLU(name='relu3'),\n",
    "        Dropout(0.5, name='dropout3'),\n",
    "\n",
    "        Dense(units=Y_train.shape[1], kernel_regularizer=l2(1e-4), name='Fully4'),\n",
    "    ])\n",
    "\n",
    "    # Compile the model with SGD optimizer and mean squared error loss\n",
    "    optimizer = SGD(learning_rate=1e-1, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "\n",
    "    # ------------------ Learning Rate Scheduler ------------------ #\n",
    "    def lr_schedule(epoch, lr):\n",
    "        if epoch > 0 and epoch % 3 == 0:\n",
    "            return lr * 0.5  # Drop learning rate by factor of 0.5 every 3 epochs\n",
    "        return lr\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    # ------------------ TensorBoard Callback ------------------ #\n",
    "    tensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n",
    "\n",
    "    # ------------------ Training Options ------------------ #\n",
    "    verbose_frequency = max(1, training_size // mini_batch_size)\n",
    "    progbar_logger = ProgbarLogger(count_mode='samples')\n",
    "\n",
    "    # ------------------ DL Model Training ------------------ #\n",
    "    print(\"Start DL training...\")\n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        X_train, Y_train,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        batch_size=mini_batch_size,\n",
    "        epochs=max_epochs,\n",
    "        shuffle=True,  # Shuffle data at each epoch\n",
    "        callbacks=[lr_scheduler, tensorboard_callback, progbar_logger],\n",
    "        verbose=1\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"Training completed in {elapsed_time / 60:.2f} minutes.\")\n",
    "\n",
    "    # ------------------ DL Model Prediction ------------------ #\n",
    "    print(\"Start DL prediction for Figure 12...\")\n",
    "    Y_predicted = model.predict(X_val)\n",
    "    print(\"Done\")\n",
    "\n",
    "    print(f\"Predicted output shape: {Y_predicted.shape}\")\n",
    "\n",
    "    return model, history, Y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed70c64d-2e2a-4c78-92da-c841335d0364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample: [0.5488135  0.67781654 0.31179588 0.9065555  0.4012595  0.31038083\n",
      " 0.17465839 0.37321596]\n",
      "Using GPU: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "---> DL Beamforming for Training_Size 80\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFirst sample: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDL_input_reshaped[:,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m,\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Call the training function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model, history, Y_predicted = \u001b[43mdl_training_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDL_input_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDL_output_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[32m     33\u001b[39m model.save(\u001b[33m\"\u001b[39m\u001b[33mtrained_model.h5\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mdl_training_4\u001b[39m\u001b[34m(DL_input_reshaped, DL_output_reshaped, training_size, validation_size, mini_batch_size, max_epochs, use_gpu)\u001b[39m\n\u001b[32m     28\u001b[39m Y = DL_output_reshaped.reshape(DL_output_reshaped.shape[\u001b[32m0\u001b[39m], -\u001b[32m1\u001b[39m).astype(np.float32)\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Split the dataset into training and validation sets\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m X_train, X_val, Y_train, Y_val = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Normalize the training data (zero-center normalization)\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Documentation StandardScaler: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m#  with_mean: default=True, If True, center the data before scaling. \u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m#  with_std: default=True, If True, scale the data to unit variance (or equivalently, unit standard deviation).\u001b[39;00m\n\u001b[32m     37\u001b[39m scaler = StandardScaler(with_std=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# To match Matlab imageInputLayer normalization behavior\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2848\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2848\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2851\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2852\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2853\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/validation.py:532\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [8, 1]"
     ]
    }
   ],
   "source": [
    "# ------------------ Example Usage ------------------ #\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    base_folder = 'C:/Users/Work/Desktop/deepMIMO/RIS/DeepMIMOv1-LIS-DeepLearning-Taha/'\n",
    "    output_folder = base_folder+'Output Python/'\n",
    "\n",
    "    seed = 0\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    simulate_data = 1\n",
    "\n",
    "    if simulate_data == 1:\n",
    "        # Simulated data for testing purposes\n",
    "        dataset_size = 100\n",
    "        training_size = 80 \n",
    "        validation_size = 20\n",
    "        M = 8\n",
    "    else:\n",
    "        dataset_size = 36200\n",
    "        training_size = 30000\n",
    "        validation_size = 6200\n",
    "        M = 64*64 # 4096\n",
    "\n",
    "    DL_input_reshaped = np.random.rand(M, 1, 1, dataset_size) \n",
    "    DL_output_reshaped = np.random.rand(1, 1, M, dataset_size)\n",
    "\n",
    "    print(f\"First sample: {DL_input_reshaped[:,0,0,0]}\")\n",
    "\n",
    "    # Call the training function\n",
    "    model, history, Y_predicted = dl_training_4(DL_input_reshaped, DL_output_reshaped, training_size, validation_size)\n",
    "\n",
    "    # Save the trained model\n",
    "    model.save(\"trained_model.h5\")\n",
    "    print(\"Model saved as 'trained_model.h5'\")\n",
    "\n",
    "    # Save history and Y_predicted in .mat format to be imported in Matlab later\n",
    "    sio.savemat(output_folder + 'history.mat', {'history': history.history})\n",
    "    sio.savemat(output_folder + 'Y_predicted.mat', {'Y_predicted': Y_predicted})\n",
    "    print(f\"Y_predicted saved as 'Y_predicted.mat' in {output_folder}\")\n",
    " \n",
    "    #np.save(os.path.join(output_folder, 'history.npy'), history.history)\n",
    "    #np.save(os.path.join(output_folder, 'Y_predicted.npy'), Y_predicted)\n",
    "    #print(\"History and Y_predicted saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e928084-71b4-4ae8-b097-47c2b1d40c68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train, X_val, Y_train, Y_val = train_test_split(\u001b[43mX\u001b[49m, Y, test_size=validation_size / (training_size + validation_size), random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=validation_size / (training_size + validation_size), random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b262e523-ea71-46e5-b463-ee09375768c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])\n",
    "b = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a61e2cb-38c0-42f5-bde0-59e6fc0c7f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a850c4e4-2fff-460d-b2be-d47a782cc0d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(0.2)` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m x, y = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2848\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2846\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2848\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2850\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2851\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2852\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2853\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/validation.py:532\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    502\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    503\u001b[39m \n\u001b[32m    504\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    529\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    531\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/validation.py:472\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_consistent_length\u001b[39m(*arrays):\n\u001b[32m    455\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[32m    456\u001b[39m \n\u001b[32m    457\u001b[39m \u001b[33;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m \u001b[33;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     lengths = [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    473\u001b[39m     uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/deepmimo/lib/python3.12/site-packages/sklearn/utils/validation.py:399\u001b[39m, in \u001b[36m_num_samples\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x.shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x.shape) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    400\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInput should have at least 1 dimension i.e. satisfy \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    401\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`len(x.shape) > 0`, got scalar `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    402\u001b[39m         )\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[32m    404\u001b[39m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[32m    405\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x.shape[\u001b[32m0\u001b[39m], numbers.Integral):\n",
      "\u001b[31mTypeError\u001b[39m: Input should have at least 1 dimension i.e. satisfy `len(x.shape) > 0`, got scalar `array(0.2)` instead."
     ]
    }
   ],
   "source": [
    "x, y = train_test_split(a,b,0.2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fc106-6620-4fb4-bd7a-18dfbc49978b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
